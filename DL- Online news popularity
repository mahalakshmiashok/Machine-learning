```{r}
library(h2o)
localH2O = h2o.init(ip = "localhost", port = 453, startH2O = TRUE,min_mem_size = "3g")
birds.hex <- h2o.importFile("C:/Manipal - Final Project/OnlineNewsPopularity/OnlineNewsPopularity - Copy.csv")
str(birds.hex)
birds.hex$shares <-ifelse(birds.hex$shares>1400,1,0)
birds.hex$shares <- as.factor(birds.hex$shares)
str(birds.hex)
h2o.levels(birds.hex$shares)
set.seed(123)
auto_splits <- h2o.splitFrame(data = birds.hex,ratios = 0.8)
train <- auto_splits[[1]]
test <- auto_splits[[2]]
y <- "shares" 
x <- setdiff(names(birds.hex),c(y))

# 1.Basic generalised linear model
glm_fit1 <- h2o.glm(x = x, y = y, training_frame = train,model_id = "glm_fit1",family = "binomial")
glm_perf1 <- h2o.performance(model = glm_fit1,newdata = test)

glm_perf1

h2o.auc(glm_perf1)

#2.Random Forest
rf_fit1 <- h2o.randomForest(x = x,y = y, training_frame = train, model_id = "rf_fit1",seed = 1)
rf_perf1 <- h2o.performance(model = rf_fit1,newdata = test)

rf_perf1
h2o.auc(rf_perf1)

#3.Gradient boosting

gbm_fit1 <- h2o.gbm(x = x,y = y, training_frame = train, model_id = "gbm_fit1",seed = 1)
gbm_perf1 <- h2o.performance(model = gbm_fit1,newdata = test)
gbm_perf1
h2o.auc(gbm_perf1)

#4.Deep Learning

dl_fit1 <- h2o.deeplearning(x = x,y = y, training_frame = train, model_id = "dl_fit1",seed = 1)
dl_perf1 <- h2o.performance(model = dl_fit1,newdata = test)
dl_perf1
h2o.auc(dl_perf1)

#5.NaiveBayes

nb_fit1 <- h2o.naiveBayes(x = x,y = y, training_frame = train, model_id = "nb_fit1", seed = 1)
nb_perf1 <- h2o.performance(model = nb_fit1,newdata = test)
nb_perf1
h2o.auc(nb_perf1)

#6.Automl
am_fit1 <- h2o.automl(x = x,y = y, training_frame = train, max_runtime_secs = 30)
lb <- am_fit1@leaderboard
lb
am_fit1@leader
pred <-h2o.predict(am_fit1,test)
pred

#AUC for all the models
# Generalized Linear Model
h2o.auc(glm_perf1)
# RandomForest
h2o.auc(rf_perf1)
# Gradient Boost model
h2o.auc(gbm_perf1)
# Deep Learning
h2o.auc(dl_perf1)
# Naive Bayes
h2o.auc(nb_perf1)
```
